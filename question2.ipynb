{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model A指標計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision, recall and f1-score for label 真\n",
      "The precision for label 真 is: 0.7144\n",
      "The recall for label 真 is: 0.5969\n",
      "The f1-score for label 真 is: 0.6504\n",
      "\n",
      "\n",
      "precision, recall and f1-score for label 假\n",
      "The precision for label 假 is: 0.9262\n",
      "The recall for label 假 is: 0.9550\n",
      "The f1-score for label 假 is: 0.9404\n",
      "\n",
      "\n",
      "precision, recall and f1-score for label Average\n",
      "The precision for label Average is: 0.8203\n",
      "The recall for label Average is: 0.7759\n",
      "The f1-score for label Average is: 0.7954\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lets calculate Precision, Recall and F1 score for label 0 and 1\n",
    "#For Label 0\n",
    "tp = 853\n",
    "fp = 341\n",
    "fn = 576\n",
    "\n",
    "precision_0  = tp / (tp + fp)\n",
    "recall_0     = tp / (tp + fn)\n",
    "f1_score_0   = 2*( precision_0 * recall_0)/(precision_0 + recall_0)\n",
    "\n",
    "print('precision, recall and f1-score for label 真')\n",
    "print('The precision for label 真 is: {0:.4f}'.format(precision_0))\n",
    "print('The recall for label 真 is: {0:.4f}'.format(recall_0))\n",
    "print('The f1-score for label 真 is: {0:.4f}'.format(f1_score_0))\n",
    "print('\\n')\n",
    "\n",
    "#For Label 1 \n",
    "\n",
    "tp = 7230\n",
    "fp = 576\n",
    "fn = 341\n",
    "\n",
    "precision_1  = tp / (tp + fp)\n",
    "recall_1     = tp / (tp + fn)\n",
    "f1_score_1   = 2*( precision_1 * recall_1)/(precision_1 + recall_1)\n",
    "\n",
    "print('precision, recall and f1-score for label 假')\n",
    "print('The precision for label 假 is: {0:.4f}'.format(precision_1))\n",
    "print('The recall for label 假 is: {0:.4f}'.format(recall_1))\n",
    "print('The f1-score for label 假 is: {0:.4}'.format(f1_score_1))\n",
    "print('\\n')\n",
    "\n",
    "print('precision, recall and f1-score for label Average')\n",
    "print('The precision for label Average is: {0:.4f}'.format((precision_0+precision_1)/2))\n",
    "print('The recall for label Average is: {0:.4f}'.format((recall_0 + recall_1) / 2))\n",
    "print('The f1-score for label Average is: {0:.4f}'.format((f1_score_0 + f1_score_1) / 2))\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model B指標計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision, recall and f1-score for label 真\n",
      "The precision for label 真 is: 0.7281\n",
      "The recall for label 真 is: 0.5920\n",
      "The f1-score for label 真 is: 0.6530\n",
      "\n",
      "\n",
      "precision, recall and f1-score for label 假\n",
      "The precision for label 假 is: 0.9256\n",
      "The recall for label 假 is: 0.9583\n",
      "The f1-score for label 假 is: 0.9417\n",
      "\n",
      "\n",
      "precision, recall and f1-score for label Average\n",
      "The precision for label Average is: 0.8268\n",
      "The recall for label Average is: 0.7751\n",
      "The f1-score for label Average is: 0.7973\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lets calculate Precision, Recall and F1 score for label 0 and 1\n",
    "#For Label 0\n",
    "tp = 846\n",
    "fp = 316\n",
    "fn = 583\n",
    "\n",
    "precision_0  = tp / (tp + fp)\n",
    "recall_0     = tp / (tp + fn)\n",
    "f1_score_0   = 2*( precision_0 * recall_0)/(precision_0 + recall_0)\n",
    "\n",
    "print('precision, recall and f1-score for label 真')\n",
    "print('The precision for label 真 is: {0:.4f}'.format(precision_0))\n",
    "print('The recall for label 真 is: {0:.4f}'.format(recall_0))\n",
    "print('The f1-score for label 真 is: {0:.4f}'.format(f1_score_0))\n",
    "print('\\n')\n",
    "\n",
    "#For Label 1 \n",
    "\n",
    "tp = 7255\n",
    "fp = 583\n",
    "fn = 316\n",
    "\n",
    "precision_1  = tp / (tp + fp)\n",
    "recall_1     = tp / (tp + fn)\n",
    "f1_score_1   = 2*( precision_1 * recall_1)/(precision_1 + recall_1)\n",
    "\n",
    "print('precision, recall and f1-score for label 假')\n",
    "print('The precision for label 假 is: {0:.4f}'.format(precision_1))\n",
    "print('The recall for label 假 is: {0:.4f}'.format(recall_1))\n",
    "print('The f1-score for label 假 is: {0:.4f}'.format(f1_score_1))\n",
    "print('\\n')\n",
    "\n",
    "print('precision, recall and f1-score for label Average')\n",
    "print('The precision for label Average is: {0:.4f}'.format((precision_0+precision_1)/2))\n",
    "print('The recall for label Average is: {0:.4f}'.format((recall_0 + recall_1) / 2))\n",
    "print('The f1-score for label Average is: {0:.4f}'.format((f1_score_0 + f1_score_1) / 2))\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 兩模型比較\n",
    "#### Model A:\n",
    "##### precision, recall and f1-score for label Average \n",
    "##### The precision for label Average is: 0.8203\n",
    "##### The recall for label Average is: 0.7759\n",
    "##### The f1-score for label Average is: 0.7954\n",
    "\n",
    "#### Model B:\n",
    "##### precision, recall and f1-score for label Average\n",
    "##### The precision for label Average is: 0.8268\n",
    "##### The recall for label Average is: 0.7751\n",
    "##### The f1-score for label Average is: 0.7973"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ans：\n",
    "Precision和Recall同時關注的都是True Positive（潛在分子），但是角度不一樣，\n",
    "Precision看的是在預測正向的情形下，實際的精準度是多少，叫考慮的是模型的預測能力，\n",
    "而Recall則是看在實際情況下為正向的狀況下，預測能找出多少實際正向的答案，較考慮實際正向的預測能力，\n",
    "今天此題目為訂房銷售，則代表了Recall指標相對而言比Precision指標來得重要，因為我們會比較在意的是我們在所有客戶中，能夠找出最多潛在會訂房的客戶，讓利益最大化.\n",
    "##### 因此從recall指標中可以看出ModelA 0.7759 > Model B 0.7751 因此我會選擇ModelA當作本情境的使用模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
